# Speech-Emotion-Recognition
## Introduction:
This repository handles building and training Speech Emotion Recognition System.
The basic idea behind this tool is to create and train/test a machine learning (as well as deep learning) algorithm capable of recognising and detecting human emotions from speech.
This is useful in a variety of industries, including product recommendation, affective computing, and so on.

## Prerequisites:
#### Python 3.6+
#### Python Libraries:
Numpy
Pandas
Matplotlib
Seaborn
Sckit-Learn
Keras
Librosa

## Dataset:
This repository used 3 datasets which are downloaded from kaggle.
#### RAVDESS : 
The Ryson Audio-Visual Database of Emotional Speech and Song that contains 24 actors (12 male, 12 female), vocalizing two lexically-matched statements in a neutral North American accent.
#### CREMA-D :
Crowd Sourced Emotional Multimodal Actors Dataset (CREMA-D) is a data set of 7,442 original clips from 91 actors. These clips were from 48 male and 43 female actors between the ages of 20 and 74 coming from a variety of races and ethnicities.
#### SAVEE :
speech emotion annotated data for emotion recognition systems is a data set of four native English male speakers (identified as DC, JE, JK, KL), postgraduate students and researchers at the University of Surrey aged from 27 to 31 years.

## Dataset Download Link:
SAVEE: https://www.kaggle.com/datasets/barelydedicated/savee-database
CREMA-D: https://www.kaggle.com/datasets/ejlok1/cremad
RAVDESS: https://www.kaggle.com/datasets/uwrfkaggler/ravdess-emotional-speech-audio






